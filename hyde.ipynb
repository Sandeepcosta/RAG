{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: elasticsearch in ./env/lib/python3.12/site-packages (8.17.1)\n",
      "Requirement already satisfied: fitz in ./env/lib/python3.12/site-packages (0.0.1.dev2)\n",
      "Requirement already satisfied: sentence-transformers in ./env/lib/python3.12/site-packages (3.4.1)\n",
      "Requirement already satisfied: numpy in ./env/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: elastic-transport<9,>=8.15.1 in ./env/lib/python3.12/site-packages (from elasticsearch) (8.17.0)\n",
      "Requirement already satisfied: configobj in ./env/lib/python3.12/site-packages (from fitz) (5.0.9)\n",
      "Requirement already satisfied: configparser in ./env/lib/python3.12/site-packages (from fitz) (7.1.0)\n",
      "Requirement already satisfied: httplib2 in ./env/lib/python3.12/site-packages (from fitz) (0.22.0)\n",
      "Requirement already satisfied: nibabel in ./env/lib/python3.12/site-packages (from fitz) (5.3.2)\n",
      "Requirement already satisfied: nipype in ./env/lib/python3.12/site-packages (from fitz) (1.9.2)\n",
      "Requirement already satisfied: pandas in ./env/lib/python3.12/site-packages (from fitz) (2.2.3)\n",
      "Requirement already satisfied: pyxnat in ./env/lib/python3.12/site-packages (from fitz) (1.6.3)\n",
      "Requirement already satisfied: scipy in ./env/lib/python3.12/site-packages (from fitz) (1.15.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./env/lib/python3.12/site-packages (from sentence-transformers) (4.49.0)\n",
      "Requirement already satisfied: tqdm in ./env/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in ./env/lib/python3.12/site-packages (from sentence-transformers) (2.6.0)\n",
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.12/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./env/lib/python3.12/site-packages (from sentence-transformers) (0.29.1)\n",
      "Requirement already satisfied: Pillow in ./env/lib/python3.12/site-packages (from sentence-transformers) (11.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.26.2 in ./env/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2.3.0)\n",
      "Requirement already satisfied: certifi in ./env/lib/python3.12/site-packages (from elastic-transport<9,>=8.15.1->elasticsearch) (2025.1.31)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.17.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: networkx in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.5)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (75.8.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./env/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./env/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./env/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in ./env/lib/python3.12/site-packages (from httplib2->fitz) (3.2.1)\n",
      "Requirement already satisfied: click>=6.6.0 in ./env/lib/python3.12/site-packages (from nipype->fitz) (8.1.8)\n",
      "Requirement already satisfied: prov>=1.5.2 in ./env/lib/python3.12/site-packages (from nipype->fitz) (2.0.1)\n",
      "Requirement already satisfied: pydot>=1.2.3 in ./env/lib/python3.12/site-packages (from nipype->fitz) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in ./env/lib/python3.12/site-packages (from nipype->fitz) (2.9.0.post0)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in ./env/lib/python3.12/site-packages (from nipype->fitz) (6.3.2)\n",
      "Requirement already satisfied: simplejson>=3.8.0 in ./env/lib/python3.12/site-packages (from nipype->fitz) (3.20.1)\n",
      "Requirement already satisfied: traits>=6.2 in ./env/lib/python3.12/site-packages (from nipype->fitz) (7.0.2)\n",
      "Requirement already satisfied: acres in ./env/lib/python3.12/site-packages (from nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: etelemetry>=0.3.1 in ./env/lib/python3.12/site-packages (from nipype->fitz) (0.3.1)\n",
      "Requirement already satisfied: looseversion!=1.2 in ./env/lib/python3.12/site-packages (from nipype->fitz) (1.3.0)\n",
      "Requirement already satisfied: puremagic in ./env/lib/python3.12/site-packages (from nipype->fitz) (1.28)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./env/lib/python3.12/site-packages (from pandas->fitz) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./env/lib/python3.12/site-packages (from pandas->fitz) (2025.1)\n",
      "Requirement already satisfied: lxml>=4.3 in ./env/lib/python3.12/site-packages (from pyxnat->fitz) (5.3.1)\n",
      "Requirement already satisfied: pathlib>=1.0 in ./env/lib/python3.12/site-packages (from pyxnat->fitz) (1.0.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.12/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: ci-info>=0.2 in ./env/lib/python3.12/site-packages (from etelemetry>=0.3.1->nipype->fitz) (0.3.0)\n",
      "Requirement already satisfied: six>=1.5 in ./env/lib/python3.12/site-packages (from python-dateutil>=2.2->nipype->fitz) (1.17.0)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in ./env/lib/python3.12/site-packages (from rdflib>=5.0.0->nipype->fitz) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./env/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install elasticsearch fitz sentence-transformers numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'rag_hyde_advance' already exists.\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "\n",
    "es = Elasticsearch(\"http://11.0.0.145:9200/\")\n",
    "\n",
    "# Define index with embedding field\n",
    "index_name = \"rag_hyde_advance\"\n",
    "\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"file_name\": {\"type\": \"text\"},\n",
    "            \"chunk_id\": {\"type\": \"integer\"},\n",
    "            \"content\": {\"type\": \"text\"},\n",
    "            \"embedding\": {\"type\": \"dense_vector\", \"dims\": 384}  # Dimension of chosen embedding model\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Create index\n",
    "if not es.indices.exists(index=index_name):\n",
    "    es.indices.create(index=index_name, body=mapping)\n",
    "    print(f\"Index '{index_name}' created.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'builtins.TextSplitter' object has no attribute 'split'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 38\u001b[0m\n\u001b[1;32m     34\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m splitter\u001b[38;5;241m.\u001b[39msplit(text)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n\u001b[0;32m---> 38\u001b[0m chunks \u001b[38;5;241m=\u001b[39m \u001b[43msemantic_chunking\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_id, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(chunks):\n\u001b[1;32m     42\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m get_embedding(chunk)  \u001b[38;5;66;03m# Generate embedding\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m, in \u001b[0;36msemantic_chunking\u001b[0;34m(text, chunk_size)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msemantic_chunking\u001b[39m(text, chunk_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m):\n\u001b[1;32m     33\u001b[0m     splitter \u001b[38;5;241m=\u001b[39m TextSplitter(capacity\u001b[38;5;241m=\u001b[39mchunk_size) \u001b[38;5;66;03m# Adjust overlap if needed\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m \u001b[43msplitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m(text)\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m chunks\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'builtins.TextSplitter' object has no attribute 'split'"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "from elasticsearch import Elasticsearch\n",
    "# from textsplit.tools import ge\n",
    "# Load Hugging Face embedding model\n",
    "embedding_model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(embedding_model_name)\n",
    "embedding_model = AutoModel.from_pretrained(embedding_model_name)\n",
    "\n",
    "def get_embedding(text):\n",
    "    \"\"\"Generate embeddings using BAAI/bge-small-en-v1.5\"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = embedding_model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].squeeze().cpu().numpy()  # CLS token embedding\n",
    "    return embedding.tolist()\n",
    "\n",
    "# Read and extract text from PDF\n",
    "pdf_path = \"/home/sandeep-cc/Documents/rag/documents/Elastic_NV_Annual-Report-Fiscal-Year-2023.pdf\"\n",
    "doc = fitz.open(pdf_path)\n",
    "\n",
    "# Extract text from each page\n",
    "pdf_text = \"\\n\".join([page.get_text(\"text\") for page in doc])\n",
    "\n",
    "# \n",
    "# pdf_text=[dict(doc_obj) for doc_obj in doc]\n",
    "\n",
    "from semantic_text_splitter import TextSplitter\n",
    "\n",
    "def semantic_chunking(text, chunk_size=500):\n",
    "    splitter = TextSplitter(capacity=chunk_size) # Adjust overlap if needed\n",
    "    chunks = splitter.split(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "chunks = semantic_chunking(pdf_text, chunk_size=500)\n",
    "\n",
    "\n",
    "for chunk_id, chunk in enumerate(chunks):\n",
    "    embedding = get_embedding(chunk)  # Generate embedding\n",
    "    \n",
    "    document = {\n",
    "        \"file_name\": pdf_path.split(\"/\")[-1],\n",
    "        \"chunk_id\": chunk_id,\n",
    "        \"content\": chunk,\n",
    "        \"embedding\": embedding,\n",
    "    }\n",
    "\n",
    "    es.index(index=index_name, body=document)  # Store in Elasticsearch\n",
    "    print(f\"âœ… Indexed chunk {chunk_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Hypothetical Answer: Based on historical trends and market analysis, it is projected that the total revenue in 2023 will experience a steady growth of approximately 3.5% compared to 2022. This estimation is derived from the average growth rate over the past five years, adjusted for current economic indicators. However, please note that this is a hypothetical projection and actual figures may vary due to unforeseen market conditions or business strategies.\n",
      "\n",
      "ðŸ”¹ Retrieved Context:  make it easy for customers to expand across use cases.\n",
      "Our business has experienced rapid growth around the world. As of April 30, 2023, we had approximately 20,200 \n",
      "customers compared to over 18,600 customers and over 15,000 customers as of April 30, 2022 and 2021, respectively. Our total \n",
      "revenue was $1.1 billion, $862.4 million, and $608.5 million for the years ended April 30, 2023, 2022 and 2021, respectively, \n",
      "representing year-over-year growth of 24% for the year ended April 30, 2023 and  ...\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import requests\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from elasticsearch import Elasticsearch\n",
    "\n",
    "# IBM Mistral API Credentials\n",
    "API_TOKEN_IBM = \"qdyGtVucbt6PtoHyk5QAnFqjeat4WrbgSDcCPfk3VAyn\"\n",
    "PROJECT_ID_IBM = \"2f606c5f-f67f-4397-8635-6ca6358f8440\"\n",
    "\n",
    "# Authenticate with IBM Cloud\n",
    "authenticator = IAMAuthenticator(API_TOKEN_IBM)\n",
    "service = \"Bearer \" + authenticator.token_manager.get_token()\n",
    "\n",
    "# IBM Mistral API Endpoint\n",
    "url = \"https://us-south.ml.cloud.ibm.com/ml/v1/text/generation?version=2023-05-29\"\n",
    "splitter = TextSplitter(chunk_size=512, chunk_overlap=50)\n",
    "\n",
    "# User query\n",
    "query_text = \"total revenue 2023\"\n",
    "\n",
    "# Step 1: Generate a Hypothetical Document using IBM Mistral\n",
    "hyde_prompt = f'''\n",
    "[INST] \n",
    "You are an expert AI generating a **hypothetical yet relevant** answer based **only on the given question**.  \n",
    "Your goal is to simulate a response that **directly aligns with the queryâ€™s intent** and can aid in retrieving relevant documents.  \n",
    "**Do not include disclaimers or generic informationâ€”focus only on generating a plausible response.**  \n",
    "\n",
    "\n",
    "### Question:\n",
    "{query_text}\n",
    "\n",
    "### Hypothetical Answer:\n",
    "[/INST]\n",
    "'''\n",
    "\n",
    "\n",
    "body = {\n",
    "    \"input\": hyde_prompt,\n",
    "    \"parameters\": {\n",
    "        \"decoding_method\": \"greedy\",\n",
    "        \"max_new_tokens\": 200,\n",
    "        \"stop_sequences\": [],\n",
    "        \"repetition_penalty\": 1\n",
    "    },\n",
    "    \"model_id\": \"mistralai/mixtral-8x7b-instruct-v01\",\n",
    "    \"project_id\": PROJECT_ID_IBM,\n",
    "    \"moderations\": {\n",
    "        \"hap\": {\n",
    "            \"input\": {\"enabled\": False},\n",
    "            \"output\": {\"enabled\": False}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Content-Type\": \"application/json\",\n",
    "    \"Authorization\": service\n",
    "}\n",
    "\n",
    "response = requests.post(url, headers=headers, json=body)\n",
    "if response.status_code != 200:\n",
    "    logging.warning(f\"Status Code --> {response.status_code}\")\n",
    "    print(\"Model context window exceeded for this document\" + str(response.text))\n",
    "    exit()\n",
    "\n",
    "data = response.json()\n",
    "hypothetical_answer = data['results'][0]['generated_text']\n",
    "print(\"\\nðŸ”¹ Hypothetical Answer:\", hypothetical_answer)\n",
    "\n",
    "# Step 2: Embed the Hypothetical Document\n",
    "query_embedding = get_embedding(hypothetical_answer)\n",
    "\n",
    "# Step 3: Retrieve Relevant Chunks from Elasticsearch\n",
    "query = {\n",
    "    \"size\": 3,\n",
    "    \"query\": {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.query_vector, 'embedding') + 1.0\",\n",
    "                \"params\": {\"query_vector\": query_embedding},\n",
    "            },\n",
    "        }\n",
    "    },\n",
    "}\n",
    "\n",
    "response = es.search(index=index_name, body=query)\n",
    "retrieved_chunks = [hit[\"_source\"][\"content\"] for hit in response[\"hits\"][\"hits\"]]\n",
    "context = \"\\n\\n\".join(retrieved_chunks)\n",
    "print(\"\\nðŸ”¹ Retrieved Context:\", context[:500], \"...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Final Answer: The total revenue for the year ended April 30, 2023 was approximately $1.1 billion.\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Generate the Final Answer using IBM Mistral\n",
    "final_prompt = f'''\n",
    "[INST]  \n",
    "You are an AI assistant specializing in generating **precise answers** based **only** on the given context.  \n",
    "Your response must strictly rely on the provided informationâ€”**do not add external knowledge or assumptions**.  \n",
    "\n",
    "### **Instructions:**  \n",
    "- If the context contains a clear answer, **extract and summarize it concisely**.  \n",
    "- If the context **partially** answers the question, indicate **what is known and what is missing**.  \n",
    "- If the context **does not contain** the required answer, **explicitly state that it is not available**â€”do not guess.  \n",
    "\n",
    "### **Context:**  \n",
    "{context}  \n",
    "\n",
    "### **Question:**  \n",
    "{query_text}  \n",
    "\n",
    "### **Answer:**  \n",
    "[/INST]\n",
    "'''\n",
    "\n",
    "body[\"input\"] = final_prompt\n",
    "response = requests.post(url, headers=headers, json=body)\n",
    "\n",
    "if response.status_code != 200:\n",
    "    logging.warning(f\"Status Code --> {response.status_code}\")\n",
    "    print(\"Model context window exceeded for this document\" + str(response.text))\n",
    "    exit()\n",
    "\n",
    "data = response.json()\n",
    "final_answer = data['results'][0]['generated_text']\n",
    "print(\"\\nðŸ”¹ Final Answer:\", final_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
